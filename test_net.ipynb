{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'nngraph'\n",
    "Plot = require \"itorch.Plot\"\n",
    "lstm = {}\n",
    "include('utils.lua')\n",
    "include('LSTM.lua')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.setnumthreads(1)\n",
    "net = lstm.LSTM({num_layers=2, input_dim=2, hidden_dim=3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = torch.randn(2,4)\n",
    "result = net:forward(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grads = torch.randn(3,2,4)\n",
    "in_grads = net:backward(inputs, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01 *\n",
       "-3.1196\n",
       " 1.3718\n",
       " 3.1856\n",
       "[torch.DoubleTensor of size 3]\n",
       "\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[{{},2,4}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "self = {num_layers = 2, input_dim=2, hidden_dim=3}\n",
    "local input = nn.Identity()()\n",
    "local c_p = nn.Identity()()\n",
    "local h_p = nn.Identity()()\n",
    "local inputs = {input, c_p, h_p} -- {x_t, c_{t-1}, h_{t-1}}\n",
    "local h, c = {}, {}\n",
    "\n",
    "\n",
    "for l = 1, self.num_layers do\n",
    "    local c_l_p = nn.SelectTable(l)(c_p)\n",
    "    local h_l_p = nn.SelectTable(l)(h_p)\n",
    "    local i2h\n",
    "    if l == 1 then\n",
    "        i2h = nn.Linear(self.input_dim, 4*self.hidden_dim)(input) -- W_x * x_t + b_x\n",
    "    else\n",
    "        i2h = nn.Linear(self.hidden_dim, 4*self.hidden_dim)(h[l-1]) -- W_x * h_{t-1} + b_x\n",
    "    end\n",
    "    local h2h = nn.Linear(self.hidden_dim, 4*self.hidden_dim)(h_l_p) -- W_h * h_{t-1} + b_h  \n",
    "    -- preactivations for i_t, f_t, o_t, c_in_t (update)\n",
    "    local preacts = nn.CAddTable()({i2h, h2h}) -- i2h + h2h\n",
    "\n",
    "    -- direction of Narrow = 1 (column vector input)\n",
    "    -- nonlinear:\n",
    "    --     input, forget, and output gates get Sigmoid\n",
    "    --     state update gets Tanh\n",
    "    local all_gates = nn.Sigmoid()(nn.Narrow(1, 1, 3*self.hidden_dim)(preacts)) \n",
    "    local update = nn.Tanh()(nn.Narrow(1, 3*self.hidden_dim + 1, self.hidden_dim)(preacts))\n",
    "    -- split gates into their variables\n",
    "    local i_gate = nn.Narrow(1, 1, self.hidden_dim)(all_gates)\n",
    "    local f_gate = nn.Narrow(1, self.hidden_dim + 1, self.hidden_dim)(all_gates)\n",
    "    local o_gate = nn.Narrow(1, 2 * self.hidden_dim + 1, self.hidden_dim)(all_gates)\n",
    "    -- new state, c = f_t .* c_p + i_t .* c_in_t\n",
    "    c[l] = nn.CAddTable()({\n",
    "            nn.CMulTable()({f_gate, c_l_p}),\n",
    "            nn.CMulTable()({i_gate, update})\n",
    "        })\n",
    "    -- new hidden, h = o_t .* Tanh(c)\n",
    "    h[l] = nn.CMulTable()({\n",
    "            o_gate,\n",
    "            nn.Tanh()(c[l])\n",
    "        })\n",
    "end\n",
    "local outputs = {nn.Identity()(c), nn.Identity()(h)} -- output new state c, and new hidden h\n",
    "\n",
    "cell = nn.gModule(inputs, outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = cell:forward({\n",
    "        torch.Tensor{1,2}, \n",
    "        {torch.Tensor{1,2,3},torch.Tensor{1,2,3}}, \n",
    "        {torch.Tensor{1,2,3},torch.Tensor{1,2,3}}\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 3\n",
       "      2 : DoubleTensor - size: 3\n",
       "    }\n",
       "  2 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 3\n",
       "      2 : DoubleTensor - size: 3\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 2\n",
       "  2 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 3\n",
       "      2 : DoubleTensor - size: 3\n",
       "    }\n",
       "  3 : \n",
       "    {\n",
       "      1 : DoubleTensor - size: 3\n",
       "      2 : DoubleTensor - size: 3\n",
       "    }\n",
       "}\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell:backward({torch.Tensor{1,2}, {torch.Tensor{1,2,3},torch.Tensor{1,2,3}}, {torch.Tensor{1,2,3},torch.Tensor{1,2,3}}},\n",
    "    {{torch.randn(3), torch.randn(3)}, {torch.randn(3), torch.randn(3)}}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
